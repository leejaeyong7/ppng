<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>PPNG Demo</title>
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/themes/prism.min.css">
    
    <script type="module" crossorigin src="/ppng/assets/main-bc090053.js"></script>
    <link rel="modulepreload" crossorigin href="/ppng/assets/modulepreload-polyfill-3cfb730f.js">
    <link rel="stylesheet" href="/ppng/assets/index-dcf8f4b2.css">
  </head>
    <body style="display:block; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;" >
    <div id="main" class="container">
      <!-- title -->
      <div class="row">
        <h2 class="col-md-12 text-center"><b>Plenoptic PNG</b>: Real-time Neural Radiance Fields in 150KB</h2>
      </div>
      <!-- Venue -->
      <div class="row">
        <h4 class="col-md-12 text-center">In Submission</h4>
      </div>
      <!-- Authors -->
      <div class="row">
        <h6 class="col-md-12 text-center">
          <span><a href="https://jyl.kr">Jae Yong Lee</a></span><sup>1*</sup>, 
          <span><a href="https://yuqunw.github.io/">Yuqun Wu</a></span><sup>1</sup>, 
          <span><a href="https://zouchuhang.github.io/">Chuhang Zou</a></span><sup>2</sup>, 
          <span><a href="https://dhoiem.cs.illinois.edu/">Derek Hoiem</a></span><sup>1</sup>, 
          <span><a href="https://shenlong.web.illinois.edu/">Shenlong Wang</a></span><sup>1</sup>, 
        </h6>
      </div>
      <!-- TODO: Affiliations -->
      <div class="row text-center">
        <h8 class="col-md-12 text-center">
          <sup>1</sup>UIUC  
          <span style="padding-left:10px;"></span>
          <sup>2</sup>Amazon Inc.  
        </h8>
        <h8 class="col-md-12 text-center">
          <sup>*</sup>Currently in Apple Inc.
        </h8>
      </div>
      <!-- Links -->
      <br>
      <div class="row text-center">
        <h8 class="col-md-12 text-center">
          <a href="https://github.com/leejaeyong7/ppng" class="text-decoration-none">
            <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
                <path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27s1.36.09 2 .27c1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.01 8.01 0 0 0 16 8c0-4.42-3.58-8-8-8"/>
            </svg>
          </a>
          <span style="padding-left:10px;"></span>
          <a href="https://arxiv.org/abs/2409.15689" class="text-decoration-none">
            <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" fill="currentColor" class="bi bi-newspaper" viewBox="0 0 16 16">
              <path d="M0 2.5A1.5 1.5 0 0 1 1.5 1h11A1.5 1.5 0 0 1 14 2.5v10.528c0 .3-.05.654-.238.972h.738a.5.5 0 0 0 .5-.5v-9a.5.5 0 0 1 1 0v9a1.5 1.5 0 0 1-1.5 1.5H1.497A1.497 1.497 0 0 1 0 13.5zM12 14c.37 0 .654-.211.853-.441.092-.106.147-.279.147-.531V2.5a.5.5 0 0 0-.5-.5h-11a.5.5 0 0 0-.5.5v11c0 .278.223.5.497.5z"/>
              <path d="M2 3h10v2H2zm0 3h4v3H2zm0 4h4v1H2zm0 2h4v1H2zm5-6h2v1H7zm3 0h2v1h-2zM7 8h2v1H7zm3 0h2v1h-2zm-3 2h2v1H7zm3 0h2v1h-2zm-3 2h2v1H7zm3 0h2v1h-2z"/>
            </svg>
          </a>
        </h8>
      </div>
      <br>
      <!-- Abstract -->
      <div class="row">
        <div class="col-md-8 offset-md-2">
          <h3>Abstract</h3>
          <p>
            The goal of Plenoptic PNG (PPNG) is to encode a 3D scene into an <it>extremely compact</it> representation from 2D images and to enable its transmittance, decoding and rendering in real-time across various platforms.
            Despite the progress in NeRFs and Gaussian Splats, their large model size and specialized renderers make it challenging to distribute free-viewpoint 3D content as easily as images. 
            To address this, we have designed a novel 3D representation that encodes the plenoptic function into sinusoidal function indexed dense volumes. This approach facilitates feature sharing across different locations, improving compactness over traditional spatial voxels. 
            The memory footprint of the dense 3D feature grid can be further reduced using spatial decomposition techniques. This design combines the strengths of spatial hashing functions and voxel decomposition, resulting in a model size as small as 150 KB for each 3D scene. 
            Moreover, PPNG features a lightweight rendering pipeline with only 300 lines of code that decodes its representation into standard GL textures and fragment shaders. This enables real-time rendering using the traditional GL pipeline, ensuring universal compatibility and efficiency across various platforms without additional dependencies.
          </p>
        </div>
      </div>
      <!-- Figures -->
      <div class="row">
        <h3 class="col-md-8 offset-md-2">Training</h3>
        <p class="col-md-8 offset-md-2">
          Training PPNG models can be done with a CUDA capable devices. 
          We implemented PPNG 1, 2 and 3 on <a href="https://github.com/leejaeyong7/tiny-cuda-nn">tiny-cuda-nn</a>, and ported on <a href="https://github.com/leejaeyong7/instant-ngp">Instant-NGP</a> platform.
          Typically, the training takes around up to 5 minute (PPNG-3) to 13 minutes (PPNG-1) to complete.
          We provide code to translate trained model weights (.ingp files) into customized format (.ppng files). The translation is does not require huge computation and is done near instantly. 
        </p>
        <h3 class="col-md-8 offset-md-2">Usage</h3>
        <p class="col-md-8 offset-md-2">
          Once trained and translated, PPNG can be easily integrated to browsers supporting <a href="https://get.webgl.org/webgl2/">WebGL 2</a>. 
          All Demo pages are implemented based on the custom component <code>ppng-viewer</code> that can be used as follows:
        </p>
        <div class="col-md-8 offset-md-2">
          <pre><code class="language-html"> &lt;ppng-viewer src="/path_to_ppng_file.ppng" width="400" height="400" &gt;&lt;/ppng-viewer&gt;</code></pre>
        </div>
      </div>
      <!-- Demo -->
      <div class="row">

        <div class="col-md-8 offset-md-2">
          <h3>Real-Time Demo</h3>
          <p>
            We provide real-time demo of PPNG on various datasets. For each page, we have 3 different models with different quality and performance trade-offs.
          </p>
          <ul>
            <li>
              P1 represents PPNG-1, our lightest, CP-decmposed version of PPNG-3 (with 128KB model size). 
            </li>
            <li>
            P2 represents PPNG-2, an intermediate, tri-plane decomposed version of PPNG-3 (with 2.46 MB model size). 
            </li>
            <li>
            P3 represents original PPNG-3 without any decomposition (with 32.8 MB model size).
            </li>
          </ul>
          <p>
            Each model has RLE encoded occupancy grid cache which are around 15~100 KB for object datasets and 400~500 KB for 360 datasets. 
            <br>
            <u>(Note that P3 is not available for some datasets scenes due to size limits in github pages.)</u>
          </p>
          <p>
            To demonstrate our efficiency, we provide 2 different ways to load the model.
            <b>All Objects</b> section loads all objects in the dataset at the same time. It will load 4 to 8 objects simultaneously depending on the dataset. 
            <br>
            <u>(Warning! This may take a while to load for P3!)</u>
            <br>
            <b>Single Object</b> section loads single object in each dataset with larger render size.
          </p>
        </div>
      </div>
      <div class="row">
          <div class="col-md-8 offset-md-2">
            <h4>All Objects</h4>
            Loads all objects in the dataset at the same time!
          </div>
          <figure class="figure col-md-2 offset-md-2">
            <!-- hack for vite. use base-pointer to get the base url -->
            <img id="base-pointer" src="/ppng/preview/NeRFSynthetic.jpg" alt="" class="figure-img img-fluid rounded">
            <figcaption>
              Synthetic NeRF
              <br>
              <a href="presets/nerf_1.html"><small>P1</small></a>
              <a href="presets/nerf_2.html"><small>P2</small></a>
              <a href="presets/nerf_3.html"><small>P3</small></a>
              <!-- <a href="#" style="color: gray;" data-bs-toggle="tooltip" data-bs-title="Disabled due to size limits!"><small>P3</small></a> -->
            </figcaption>
          </figure>
          <figure class="figure col-md-2">
            <img src="/ppng/preview/Synthetic_NSVF.jpg" alt="" class="figure-img img-fluid rounded">
            <figcaption>
              Synthetic NSVF
              <br>
              <a href="presets/nsvf_1.html"><small>P1</small></a>
              <a href="presets/nsvf_2.html"><small>P2</small></a>
              <a href="presets/nsvf_3.html"><small>P3</small></a>
            </figcaption>
          </figure>
          <figure class="figure col-md-2">
            <img src="/ppng/preview/BlendedMVS.jpg" alt="" class="figure-img img-fluid rounded">
            <figcaption>
              Blended MVS
              <br>
              <a href="presets/blended_mvs_1.html"><small>P1</small></a>
              <a href="presets/blended_mvs_2.html"><small>P2</small></a>
              <!-- <a href="presets/blended_mvs_3.html"><small>P3</small></a> -->
              <a href="#" style="color: gray;" data-bs-toggle="tooltip" data-bs-title="Disabled due to size limits!"><small>P3</small></a>
            </figcaption>
          </figure>
          <figure class="figure col-md-2">
            <img src="/ppng/preview/TanksAndTemple.jpg" alt="" class="figure-img img-fluid rounded">
            <figcaption>
              Tanks and Temples
              <br>
              <a href="presets/tnt_1.html"><small>P1</small></a>
              <a href="presets/tnt_2.html"><small>P2</small></a>
              <a href="presets/tnt_3.html"><small>P3</small></a>
            </figcaption>
          </figure>
          <figure class="figure col-md-2 offset-md-2">
            <img src="/ppng/preview/360_v2.jpg" alt="" class="figure-img img-fluid rounded">
            <figcaption>
              MIPNeRF 360
              <br>
              <a href="presets/mipnerf_1.html"><small>P1</small></a>
              <a href="presets/mipnerf_2.html"><small>P2</small></a>
              <a href="presets/mipnerf_3.html"><small>P3</small></a>
            </figcaption>
          </figure>
      </div>
      <div class="row">
        <div class="col-md-8 offset-md-2">
          <h4>Single Object</h4>
          Loads single object with larger render size.
        </div>
      </div>
      
      <div id="ppng-objects" class="row">

      </div>
      <!-- TODO: Citation -->
      <div class="row">
        <div class="col-md-8 offset-md-2">
          <h3>Citation</h3>
          We will release citation information once the paper is accepted.
        </div>
      </div>
      <!-- TODO: Acknowledgement -->
      <div class="row">
      </div>
      <!-- page formatting-->
      <div class="row" style="margin-bottom: 100px;">
      </div>
    </div>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/prismjs@1.29.0/prism.min.js"></script>
    
    
  </body>
</html>